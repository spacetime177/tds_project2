# tds_project2
Automated Data Analysis and Visualization with GPT-4o-Mini for Advanced Insights

Project Overview

This project focuses on the development of an advanced Python-based automation system designed to analyze, visualize, and narrate insights from any given dataset. By integrating a powerful Large Language Model (LLM) and state-of-the-art data processing and visualization techniques, the system automatically generates comprehensive Markdown reports with rich visual representations. It is versatile and compatible with any CSV dataset, enabling dynamic, in-depth analysis tailored to a wide range of needs.

Key Features

Comprehensive Automated Data Analysis Automatically performs detailed summary statistics, identifies missing values, and detects anomalies with high precision. Analyzes correlations and detects latent patterns through sophisticated statistical techniques like clustering. Utilizes GPT-4o-Mini for advanced insights and recommendations on analytical methods and improvements.

Dynamic Visualization Generation Automatically generates 1–3 visually compelling charts in PNG format tailored to the dataset's specific attributes. Supports a diverse set of visualizations, including heatmaps, bar charts, and more, based on the analysis results.

Insightful Narrative and Report Generation Uses GPT-4o-Mini to craft structured and coherent narratives that explain dataset characteristics, analysis methodologies, key findings, and broader implications. Outputs a cohesive Markdown report (README.md) integrating the insights with corresponding visual elements for easy interpretation.

Optimized LLM Resource Usage Preprocesses and summarizes data before querying the LLM, reducing direct dataset transfers and optimizing token usage. Ensures that analyses are detailed and precise while minimizing resource consumption.

Universal Compatibility with CSV Datasets Capable of adapting dynamically to datasets with varying column types, distributions, and complexities, ensuring robust and scalable performance across a wide variety of datasets.

Self-Contained Execution Functions as a standalone Python script (autolysis.py), requiring only standard Python libraries—no external dependencies are needed.

Simplified Execution and Integration The script can be executed easily via the uv CLI tool with a single command for end-to-end functionality: uv run autolysis.py dataset.csv Workflow

Data Preprocessing Reads the input CSV file, extracting metadata such as column names, data types, and sample values. Identifies missing data points, anomalies, and potential outliers for further analysis.

Exploratory Data Analysis (EDA) Performs a full suite of exploratory analyses, including: Statistical summaries of all variables. Correlation matrix generation to evaluate relationships between variables. Detection of anomalies and outliers. Clustering analysis to group data points with similar traits.

LLM Integration for Enriched Insights Transmits dataset metadata and EDA results to GPT-4o-Mini for deeper analysis. Incorporates GPT-generated Python code suggestions or supplemental analyses to enhance the workflow.

Visualization Creation Generates high-quality visualizations using libraries like Seaborn and Matplotlib. Saves visualizations as PNG files in the working directory for easy access and integration into reports.

Narrative and Report Generation Leverages GPT-4o-Mini to generate a structured Markdown report that includes: An overview of the dataset. Methodologies and techniques used for analysis. Key findings and their broader implications. Embedded visualizations to enhance understanding.

Output Files The system produces the following deliverables:

README.md: A comprehensive Markdown report summarizing the analysis and including embedded visualizations. *.png: PNG files containing the visualizations generated during analysis. Sample Datasets

The system has been thoroughly tested with several sample datasets, including:

goodreads.csv: A dataset of 10,000 books from GoodReads, including genres, ratings, and metadata. happiness.csv: Global data from the World Happiness Report, featuring happiness indices and contributing factors. media.csv: Faculty evaluations of movies, TV shows, and books, blending subjective ratings with objective data. Usage Instructions

Clone the repository and navigate to the project directory. Set up the required environment variable for authentication: export AIPROXY_TOKEN=your-token-here Run the script using the uv CLI tool: uv run autolysis.py dataset.csv After execution, the following files will be available in the working directory: README.md: The detailed Markdown report. *.png: The visualizations in PNG format. Technical Notes

LLM Integration for Optimized Utilization: The system makes multiple LLM queries to generate detailed insights and recommendations. The function-calling capabilities of OpenAI’s API are used for precise results and resource optimization. Environment Configuration: The AIPROXY_TOKEN environment variable is required for LLM authentication and API access. Visualization Tools: The system uses Seaborn and Matplotlib for the generation of visually appealing and informative charts. Deliverables

Core Python Script: autolysis.py: A standalone Python script that encapsulates all functionalities. Generated Output Files: A directory for each dataset (e.g., goodreads/, happiness/, media/), containing: README.md: The Markdown report. *.png: The generated visualizations. Licensing

This project is licensed under the MIT License. For details, refer to the LICENSE file in the repository.

Conclusion This project integrates advanced data analysis techniques with the power of GPT-4o-Mini, allowing users to seamlessly automate data exploration, generate compelling visualizations, and produce detailed reports. Whether you’re analyzing simple datasets or complex data structures, this system empowers you to gain deeper insights with minimal effort, while optimizing both performance and resource utilization.
